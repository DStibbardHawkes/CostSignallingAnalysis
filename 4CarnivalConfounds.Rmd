---
title: "Cost for Signalling: Investigating Potential Experimental Confounds and Artefacts"
output: html_notebook
---

### Packages and Data

In this document we're going to examine three experimental artefacts, to see if they represent potential confounds. As ever, we'll start by loading our packages.

These analyses were last conducted on the following date:

```{r}
date()
```

If any of the packages or functions used in this analysis are now broken or depreciated, consider using the groundhog package with this date to load packages.)

```{r}
##load packages (all on CRAN; use install.packages() if first time)
library(tidyverse) #Load dplyr, ggplot and others
library(brms) #Bayesian regressions with STAN
library(tidybayes) #Useful functions for describing posterior (e.g., mean_hdi)
library(ggplot2) #Good-looking visualization package
library(bayesplot) #Quick and easy coef plots.
library(ggridges) #Fancy density ridgeplots for fancy people.
library(magrittr) #For two-way pipes
library(rstudioapi) #Allows RStudio to get the current working directory.
library(patchwork) #Easily stitch figures together with operators.
library(xtable) # Brings many types table format to the table. Used here to export LaTeX tables.  
library(ggtext) #Use HTML Elements in GGPlot
```

Next let's load the data. As before, this uses the rstudio API and requires that the appropriate .rda file be in the same folder as this script.

```{r}
setwd(dirname(getActiveDocumentContext()$path))
load("carnivaldata.rda")
load("carnivalmodels.rda")
```

In case there are any sources of (psuedo-)random variation in our functions, let's set a RNG seed.

```{r}
set.seed(42)
```

Now we can start examining those potential confounds.

# Controlling for potential experimental confounds

## Game Order

The first potential experimental artefact is game order - whether people played the hunting or the gathering game first. This has the potential to confound our game-type difference.

```{r}
FgGt <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + firstgame + Game_Type,
              prior = c(prior(normal(0, 1), class = b)),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 1, cores = 1,
              #control = list(adapt_delta = .95),
              file = "fits/FgGt",
          )

FgGt <- add_criterion(FgGt, criterion = c("loo", "waic")) 
```

Let's briefly inspect our probability-scale estimates using the fitted function.

```{r}
nd <- d %>%
  distinct(firstgame, Game_Type)

FgGtFit <- fitted(FgGt, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  unite(col = "new", c(firstgame, Game_Type), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new)) + geom_point() + geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1) + scale_y_discrete(labels= c("ForageGame_ForageFirst","HuntGame_ForageFirst", "ForageGame_HuntFirst", "HuntGame_HuntFirst"))

FgGtFit
```

As we can see, playing the hunting game first lead to an increase in probability of playing, independent of game type. Looking at the means, about 3% in absolute terms. However, the overlap between the hunt first and forage first distributions was substantial, so this could be a consequence of chance. Let's compare this model with the game type only model

```{r}
ms5 <- loo_compare(GameType, FgGt, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms5 <- model_weights(GameType, FgGt, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms5) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms5
```

As we can see, the model including first game is a represents a small improvement on the model including game type only, but the models are largely comparable. The first chosen game has a small but not substantial influence. Equivocal improvement in model fit, so probably not a substantial enough analysis to fully report in the text body.

## Prize Colour

The next question is does bracelet colour affect probability of playing. Since not all rounds had a prize, we're going to limit our selection here to those games which had bracelets.

```{r}
dbracelet <- d %>%
  filter(Prize != "NA")
```

...and we'll compare the bracelet only condition to the intercept only model.

```{r}
PrizeConditionBaseline <- brm(
  data = dbracelet, family = bernoulli,
  Played1 ~ 1,
  prior = c(prior(normal(0, 1), class = Intercept)),
  iter = 10000, warmup = 5000, cores = 4, chains = 4,
  #control = list(adapt_delta = .9),
  seed = 42,
  file = "fits/PrizeConditionBaseline"
)

PrizeConditionBaseline <- add_criterion(PrizeConditionBaseline, criterion = c("loo")) 

PrizeColor <- brm(data = dbracelet,
              family = bernoulli,
              Played1 ~ 0 + Prize,
              prior = c(prior(normal(0, 1), class = b)),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 1, cores = 1,
              #control = list(adapt_delta = .95),
              file = "fits/PrizeColor",
          )

PrizeColor <- add_criterion(PrizeColor, criterion = c("loo")) 
```

Let's briefly inspect our estimates. Only a single response variable so just a quick mcmc plot this time will do.

```{r}
mcmc_plot(PrizeColor)
```

As we can see a mild preference for red bracelets but substantial overlap between distributions. Let's compare the model including prize colour to the baseline.

```{r}
ms6 <- loo_compare(PrizeColor, PrizeConditionBaseline, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms6 <- model_weights(PrizeColor, PrizeConditionBaseline, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms6) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms6
```

Once again the results are equivocal, with some weight allotted to both models. Here the baseline is preferred. Again it appears safe to discount the importance of prize colour - it does not very substantially influence choices.

## Outcome of Previous Round

Next we'll examine impact of the outcome of the previous round. Are people more or less likely to play if they won or lost previously.

```{r}
Prv <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Previous,
              prior = c(prior(normal(0, 1), class = b)),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 1, cores = 1,
              #control = list(adapt_delta = .95),
              file = "fits/Prv",
          )

Prv <- add_criterion(Prv, criterion = c("loo", "waic")) 

```

And let's inspect our fits

```{r}
nd <- d %>%
  distinct(Previous)

PrvFit <- fitted(Prv, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  ggplot(aes(x = Estimate, y = Previous)) + geom_point() + geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1) + scale_y_discrete(labels= c("First Round","Lose", "No Data", "Win"))

PrvFit
```

The two 'no data' and 'first round' findings here are unsurprising. Where there was no data from the previous round, people had stopped. Players never took the opportunity to play in the fourth round where they had declined to play in round two. First rounds were often free, leading to an increased play probability. The big finding here is the difference between rounds that were previously won and previously lost. Here we can see clearly that losing on a previous round leads to an increased probability of playing.

However, this might be because win probabilities were higher in one or other game.

Let's dive deeper and include previous round results in the full model.

```{r}
CrGtrSrArP <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Condition + (0 + Condition | Game_Type) + (0 + Condition | sex) + (0 + Condition | AgeSplit) + (0 + Condition | Previous),
              prior = c(prior(normal(0, 1), class = b)
                        ,prior(exponential(1), class = sd, group = Game_Type)
                        ,prior(lkj(2), class = cor, group = Game_Type)
                        ,prior(exponential(1), class = sd, group = sex)
                        ,prior(lkj(2), class = cor, group = sex)
                        ,prior(exponential(1), class = sd, group = AgeSplit)
                        ,prior(lkj(2), class = cor, group = AgeSplit)
                        ,prior(exponential(1), class = sd, group = Previous)
                        ,prior(lkj(2), class = cor, group = Previous)
                        ),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 4, cores = 4,
              control = list(adapt_delta = .99),
              #This settings banish some error messages but takes a while to run. 
              #Consider adjusting if you're not using a fast CPU.
              file = "fits/CrGtrSrArP",
          )

CrGtrSrArP <- add_criterion(CrGtrSrArP, criterion = c("loo", "waic"))
```

Now let's compare this model with our full model

```{r}
ms7 <- loo_compare(CrGtrSrA, CrGtrSrArP, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms7 <- model_weights(CrGtrSrA, CrGtrSrArP, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms7) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms7
```

As we can see, adding previous round results leads to a huge increase in fit. This is unsurprising, as the variable replicates the information present in our condition variable. Also the 'NA' category almost 1:1 predicts the probability of not playing any round where participants also did not play the previous round.

What we're really interested in is the difference in playing after winning a round vs the difference in playing after losing a round. So let's create a subset of our data where actual play-outcome data are available and run these models again.

First we'll create a trimmed sample, with only WIN/LOSE data

```{r}
d_winlose <- d %>%
  filter(Previous == "WIN" | Previous == "LOSE")

```

We can use also this to calculate per round win probabilities. Fist the aim game:

```{r}
#First the aim/hunting game
d_winlose %>%
  filter(Game_Type == "HUNT") %>%
  mutate(PreviousBinary = Previous == "WIN") %>%
  group_by(factor(Round_Number)) %>%
  summarise(across(c(PreviousBinary),mean)) %>% 
    rename(
   "Round" = "factor(Round_Number)",
   "Win Proportion" = "PreviousBinary"
  ) %>%
  arrange()


```

Then the search game:

```{r}
#Then the search/gathering game
d_winlose %>%
  filter(Game_Type == "FORAGE") %>%
  mutate(PreviousBinary = Previous == "WIN") %>%
 group_by(factor(Round_Number)) %>%
  summarise(across(c(PreviousBinary),mean)) %>% 
  rename(
   "Round" = "factor(Round_Number)",
   "Win Proportion" = "PreviousBinary"
  ) %>%
  arrange()

```

Now let's run our models.

```{r}
CrGtrSrA.2 <- brm(data = d_winlose,
              family = bernoulli,
              Played1 ~ 0 + Condition + (0 + Condition | Game_Type) + (0 + Condition | sex) + (0 + Condition | AgeSplit),
              prior = c(prior(normal(0, 1), class = b)
                        ,prior(exponential(1), class = sd, group = Game_Type)
                        ,prior(lkj(2), class = cor, group = Game_Type)
                        ,prior(exponential(1), class = sd, group = sex)
                        ,prior(lkj(2), class = cor, group = sex)
                        ,prior(exponential(1), class = sd, group = AgeSplit)
                        ,prior(lkj(2), class = cor, group = AgeSplit)
                        ),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 4, cores = 4,
              control = list(adapt_delta = .99),
              #This settings banish some error messages but takes a while to run. 
              #Consider adjusting if you're not using a fast CPU.
              file = "fits/CrGtrSrA.2",
          )

CrGtrSrA.2 <- add_criterion(CrGtrSrA.2, criterion = c("loo", "waic"))

CrGtrSrArP.2 <- brm(data = d_winlose,
              family = bernoulli,
              Played1 ~ 0 + Condition + (0 + Condition | Game_Type) + (0 + Condition | sex) + (0 + Condition | AgeSplit) + (0 + Condition | Previous),
              prior = c(prior(normal(0, 1), class = b)
                        ,prior(exponential(1), class = sd, group = Game_Type)
                        ,prior(lkj(2), class = cor, group = Game_Type)
                        ,prior(exponential(1), class = sd, group = sex)
                        ,prior(lkj(2), class = cor, group = sex)
                        ,prior(exponential(1), class = sd, group = AgeSplit)
                        ,prior(lkj(2), class = cor, group = AgeSplit)
                        ,prior(exponential(1), class = sd, group = Previous)
                        ,prior(lkj(2), class = cor, group = Previous)
                        ),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 4, cores = 4,
              control = list(adapt_delta = .99),
              #This settings banish some error messages but takes a while to run. 
              #Consider adjusting if you're not using a fast CPU.
              file = "fits/CrGtrSrArP.2",
          )

CrGtrSrArP.2 <- add_criterion(CrGtrSrArP.2, criterion = c("loo", "waic"))


```

Now for another model selection

```{r}

ms8 <- loo_compare(CrGtrSrA.2, CrGtrSrArP.2, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms8 <- model_weights(CrGtrSrA.2, CrGtrSrArP.2, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms8) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms8

```

These model selection results make much more sense. Adding previous round win probabilities to this model doesn't actually greatly improve model fit - the full model excluding play probabilities is actually slightly preferred. Let's examine our fitted model predictions anyway, to see what's happening.

```{r, warning=FALSE, error=FALSE}

nd <-  d_winlose  %>% 
  distinct(AgeSplit, Condition, Game_Type, sex, Previous)

nd$Condition <- droplevels(nd$Condition)

#NewLabs <- c("P0B1F","P0B1H", "P0B0F", "P0B0H", "P1B1F","P1B1H", "P1B0F", "P1B0H")

NCrGtrSrAFitMY1 <- fitted(CrGtrSrArP.2, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M" & AgeSplit == "Younger") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = Previous)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))+
  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete() + scale_color_manual(values=c("DarkGrey", "Yellow4"))

NCrGtrSrAFitFY1 <- fitted(CrGtrSrArP.2, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F" & AgeSplit == "Younger") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = Previous)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))+
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) + scale_color_manual(values=c("DarkGrey", "Yellow4"))

NCrGtrSrAFitMO1 <- fitted(CrGtrSrArP.2, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M" & AgeSplit == "Older") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = Previous)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))+
  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete() + scale_color_manual(values=c("DarkGrey", "Yellow4"))

NCrGtrSrAFitFO1 <- fitted(CrGtrSrArP.2, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F" & AgeSplit == "Older") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = Previous)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))+
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) + scale_color_manual(values=c("DarkGrey", "Yellow4"))

NCrGtrSrAFitMY1 + NCrGtrSrAFitFY1 +
NCrGtrSrAFitMO1 + NCrGtrSrAFitFO1 +
plot_layout(ncol = 2, nrow = 2)
```

These don't have axis labels but the left column is women, and the top row is younger individuals (right = men, bottom = older). As we can see, in most cases winning or losing a previous round makes little difference. The only categories in which results seem to be trending are, in fact, those where bracelets are available. When bracelets are available, we see that losing a round appears to slightly increase the mean probability of playing again. This makes of sense - if bracelets are desired for their signalling value, there is good sense in playing until you get one.

### Camp Size

Let's also explore camp size. Games generated significant interest and, as they were necessarily conducted outside, it proved impossible to exclude onlookers. It's worth exploring whether camp size increase play probabilities.

We'll write a few more models here. First we want to see if camp size improves on the model including only condition and game type.

```{r}

CrGT <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Condition + (0 + Condition | Game_Type),
              prior = c(prior(normal(0, 1), class = b))  
              ,prior(exponential(1), class = sd, group = Game_Type)
              ,prior(lkj(2), class = cor, group = Game_Type),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 2, cores = 2,
              control = list(adapt_delta = .99),
              file = "fits/CrGT",
          )

CrGT <- add_criterion(CrGT, criterion = c("loo", "waic")) 

CCprGT <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Condition + camppop + (0 + Condition + camppop | Game_Type),
              prior = c(prior(normal(0, 1), class = b))  
              ,prior(exponential(1), class = sd, group = Game_Type)
              ,prior(lkj(2), class = cor, group = Game_Type),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 2, cores = 2,
              control = list(adapt_delta = .99),
              file = "fits/CCprGT",
          )

CCprGT <- add_criterion(CCprGT, criterion = c("loo", "waic")) 

```

Now lets visualise these findings.

```{r}
nd <-  d %>% 
  distinct(Condition, Game_Type) %>%
  mutate(camppop = min(d$camppop))

CrGTFit1 <- fitted(CCprGT, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  ggplot(aes(x = Estimate, y = Condition, color = Game_Type)) + geom_point(position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))#+
#  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete(labels= NewLabs)


nd <-  d %>% 
  distinct(Condition, Game_Type) %>%
  mutate(camppop = mean(d$camppop))

CrGTFit2 <- fitted(CCprGT, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  ggplot(aes(x = Estimate, y = Condition, color = Game_Type)) + geom_point(position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))#+
#  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete(labels= NewLabs)


nd <-  d %>% 
  distinct(Condition, Game_Type) %>%
  mutate(camppop = max(d$camppop))


CrGTFit3 <- fitted(CCprGT, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  ggplot(aes(x = Estimate, y = Condition, color = Game_Type)) + geom_point(position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))#+
#  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete(labels= NewLabs)



CrGTFit1 +
CrGTFit2 +
CrGTFit3 +
plot_layout(ncol = 1, nrow = 3)
```

Now let's compare

```{r}


ms9 <- loo_compare(CrGT, CCprGT, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms9 <- model_weights(CrGT, CCprGT, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms9) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms9

```

Of course, as camp sizes are fixed at the camp level, this variable is also providing camp-level information. As conditions (free/paid; Prize/No Prize) were set at the camp level, this potentially represents a confound and limits our ability to draw inferences from this finding. Let's try and account for this by comparing a model with camp ID and condition only, versus camp ID, condition and camp size. First let's run both models:

```{r}

CCidrGT <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Condition + campid + (0 + Condition + campid | Game_Type),
              prior = c(prior(normal(0, 1), class = b))  
              ,prior(exponential(1), class = sd, group = Game_Type)
              ,prior(lkj(2), class = cor, group = Game_Type),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 2, cores = 2,
              control = list(adapt_delta = .99),
              file = "fits/CCidrGT",
          )

CCidrGT <- add_criterion(CCidrGT, criterion = c("loo", "waic")) 


CCidCprGT <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Condition + campid + camppop + (0 + Condition + campid + camppop | Game_Type),
              prior = c(prior(normal(0, 1), class = b))  
              ,prior(exponential(1), class = sd, group = Game_Type)
              ,prior(lkj(2), class = cor, group = Game_Type),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 2, cores = 2,
              control = list(adapt_delta = .99),
              file = "fits/CCidCprGT",
          )

CCidCprGT <- add_criterion(CCidCprGT, criterion = c("loo", "waic"))  
```

Now let's conduct a model selection

```{r}


ms10 <- loo_compare(CCidrGT, CCidCprGT, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms10 <- model_weights(CCidrGT, CCidCprGT, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms10) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms10

```

As we can see, the model without camp size is far preferred, and the camp size model provides little useful information. Now, let's explore the final potential methodological artifact, round number.

## Round Number

Our final Bernoulli trials assume that each event is independent. In fact ours are aren't, because with each subsequent round the chance to play decreases. This would not be greatly problematic if each condition had the same number of rounds. However, some conditions had more rounds than others - especially because we estimated our no pay, prize condition using a single free round.

As round number should predominantly impact condition-level differences we'll start with a model that includes condition and round number.

```{r}

NCrGt <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Condition + Round_Number + (0 + Condition + Round_Number | Game_Type),
              prior = c(prior(normal(0, 1), class = b)
                        ,prior(exponential(1), class = sd, group = Game_Type)
                        ,prior(lkj(2), class = cor, group = Game_Type)),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 4, cores = 4,
              control = list(adapt_delta = .999, max_treedepth = 15),
              #This many iterations banishes some error messages but takes a while to run. 
              #Consider adjusting if you're not using a fast CPU.
              file = "fits/NCrGt",
          )

NCrGt <- add_criterion(NCrGt, criterion = c("loo", "waic")) 

```

Lets see how this compares to the 'Condition \| game_type' only model.

```{r}

ms11 <- loo_compare(NCrGt, CrGt, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)
  
ms11 <- model_weights(NCrGt, CrGt, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms11) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)
  
ms11
```

A substantial improvement. Adding round number makes a very large impact, and is worth investigating further. Let's add it to the 'full' model.

```{r}
NCrGtrSrA <- brm(data = d,
              family = bernoulli,
              Played1 ~ 0 + Round_Number + Condition + (0 + Round_Number + Condition | Game_Type) 
              + (0 + Round_Number + Condition | sex) + (0 + Round_Number + Condition | AgeSplit),
              prior = c(prior(normal(0, 1), class = b)
                        ,prior(exponential(1), class = sd, group = Game_Type)
                        ,prior(lkj(2), class = cor, group = Game_Type)
                        ,prior(exponential(1), class = sd, group = sex)
                        ,prior(lkj(2), class = cor, group = sex)
                        ,prior(exponential(1), class = sd, group = AgeSplit)
                        ,prior(lkj(2), class = cor, group = AgeSplit)
                        ),
              seed = 42,
              iter = 10000, warmup = 5000, chains = 6, cores = 6,
              control = list(adapt_delta = .999, max_treedepth = 15),
              #This settings banish some error messages but takes a while to run. 
              #Consider adjusting if you're not using a fast CPU.
              file = "fits/NCrGtrSrA",
          )

NCrGtrSrA <- add_criterion(NCrGtrSrA, criterion = c("loo", "waic"))
```

Now let's see if adding round number improves upon the full model.

```{r}
ms12 <- loo_compare(CrGtrSrA, NCrGtrSrA, criterion = "loo") %>%
  round(digits = 2) %>% 
  as.data.frame() %>% 
  select(elpd_diff,se_diff) %>% 
  rownames_to_column() %>%
  arrange(rowname)

ms12 <- model_weights(CrGtrSrA, NCrGtrSrA, weights = "loo") %>% 
  round(digits = 2) %>%
  as.data.frame() %>% 
  rownames_to_column() %>%
  arrange(rowname) %>%
  column_to_rownames("rowname") %>%
  cbind(ms12) %>%
  rename(
    Weights = ".",
    "ELPD Difference" = elpd_diff,
    "SE Difference" = "se_diff"
  ) %>%
  arrange(desc(`ELPD Difference`)) %>%
  select(-rowname)

ms12
```

Substantially, as it transpires. Since round number is continuous, the complete model will be tricky to visualize. I'm going to use what McElreath calls a triptych, showing fitted predictions for round numbers 1, 3 (the mean value) and 5.

```{r}

nd <-  d %>% 
  distinct(AgeSplit, Condition, Game_Type, sex) %>%
  mutate(Round_Number = 1)

NewLabs <- c("P0B1F","P0B1H", "P0B0F", "P0B0H", "P1B1F","P1B1H", "P1B0F", "P1B0H")

NCrGtrSrAFitM1 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))+
  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete(labels= NewLabs)

NCrGtrSrAFitF1 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9))  + 
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), legend.position = "none")

nd <-  d %>% 
  distinct(AgeSplit, Condition, Game_Type, sex) %>%
  mutate(Round_Number = 3)

NCrGtrSrAFitM3 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) +
  theme(legend.position = "none", axis.title = element_blank()) + scale_y_discrete(labels= NewLabs)


NCrGtrSrAFitF3 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) + 
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

nd <-  d %>% 
  distinct(AgeSplit, Condition, Game_Type, sex) %>%
  mutate(Round_Number = 5)

NCrGtrSrAFitM5 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "M") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) +
  theme(legend.position = "none",axis.title.y = element_blank()) + scale_y_discrete(labels= NewLabs)

NCrGtrSrAFitF5 <- fitted(NCrGtrSrA, newdata = nd, probs = c(.05,.95)) %>% 
  data.frame() %>% 
  bind_cols(nd) %>%
  filter(sex == "F") %>%
  unite(col = "new", c(Condition, Game_Type, sex), sep = "_") %>%
  ggplot(aes(x = Estimate, y = new, color = AgeSplit)) + geom_point( position = position_dodge(.9)) + 
  geom_errorbar(aes(xmin = Q5, xmax = Q95),width=0, lwd = 1,  position = position_dodge(.9)) + 
  theme(axis.title = element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), legend.position = "none")


NCrGtrSrAFitM1 + NCrGtrSrAFitF1 +
NCrGtrSrAFitM3 + NCrGtrSrAFitF3 +
NCrGtrSrAFitM5 + NCrGtrSrAFitF5 + 
plot_layout(ncol = 2, nrow = 3)

```

This is a complex model, but the outputs make sense. Here we've put women on the right column, men on the left column, and the rows (top to bottom) represent fitted estimates for rounds 1 (min), 3 (median), and 5 (max).

All of our contrasts of interest show a similar pattern to the model which did not include round number. Mean estimates are still typically higher for men than for women. Younger people of both genders are more likely to play than older people. The free rounds are all more popular than the pay rounds. The hunting game is more popular than the gathering game. But for the two pay conditions for men, the prize conditions are more popular than the no prize conditions. Unsurprisingly, the fitted estimated when round number is at its average value (i.e., round three) is very similar to the model which excluded round number. The only notable difference is some shrinkage for the free/prize rounds (to be expected as we only have round 1 data for these).

Modelling round number tells us two things. First, as expected, the probability of playing drops with each passing round. Second, the uncertainty over the pay 0, prize 1 condition (for which we only have round 1 data) decreases with each round, while the certainty for the pay conditions (which were never round 1) increases.

Since the predictions are rather similar to those of the full model, it makes more sense to report the full model in the manuscript itself. The information we're presenting in the full model is already quite complex - as adding 'round number' as a predictor doesn't alter any key findings, better to reduce the complexity in print.

Let's finish by printing out our session info.

```{r}
sessionInfo()
```
